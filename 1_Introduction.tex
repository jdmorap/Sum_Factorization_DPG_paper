\section{Introduction}

During the computation of a numerical solution to a linear boundary value problem using a Finite Element (FE) method, two major tasks are carried out by the computer processors, namely, calculation and assembly of the stiffness matrix and the load vector, and the solution of the linear system. The latter depends mostly on the size and properties of the global stiffness matrix, while the former depends more heavily on the local characteristics of every element in the mesh, as both the load vector and stiffness matrix are first computed at the element level. In higher-order finite elements the calculation of the integrals that compose such matrix and vector may become costly, since the higher the degree of a polynomial integrand, the larger the number of quadrature points needed to perform an exact (or at least a well approximated) numerical integration. Our interest in this article is to combine several results that can lead to significant savings in three-dimensional DPG computations.

In FE, every type of element can be associated to one or more families of shape functions whether for the trial space or for the test space. In two spatial dimensions, the only conventional tensor-product element is the quadrilateral, which is generated by tensor-multiplying two line segments. In 3D, the conventional element types are the hexahedron, the tetrahedron, the (triangular) prism and the pyramid (of quadrilateral base) \cite{Fuentes2015}. Out of them, the hexahedron and the prism are examples of tensor-product elements. The hexahedron is a triple tensor-product of 1D intervals, and the prism is a tensor-product of a triangle in 2D and a 1D interval. Thus, the standard shape functions for these two types of elements are tensor products of the shape functions associated to their lower-dimension generating elements.

The idea of using sum factorization for computing 2D and 3D integrals has been an established technique for spectral methods in CFD \cite{orszag1980spectral,karniadakis2013spectral}, and later adopted for $p$- and $hp$-FE with higher-order shape functions by Melenk et al \cite{melenk2001fully}. It was additionally implemented for the case of a fully automatic $hp$-adaptive FE solution of the Helmholtz equation by Kurtz \cite{kurtz2007fully}, therein delivering explicit steps to compute the matrix while keeping a low memory requirement. More recently, the tensor-product nature of the shape functions in Bernstein-B\'ezier FE and Isogeometric Analysis also motivated the extension of this integration for the stiffness matrices of those methods \cite{AinsworthBezier,antolin2015efficient}.

Use of fast integration algorithms becomes even more critical in an efficient implementation of the Discontinuous Petrov Galerkin (DPG) FE methodology. In order to see that, let us first refer to a classic Galerkin FE method in 3D. Let $p$ denote the order of polynomial basis for discretizing the solution. The algebraic structure of the final linear system reads
\begin{equation*}
    \sfB\sfu=\sfell,
\end{equation*}

\noindent with square stiffness matrix $\sfB$ of size $\mcO(p^3)\times\mcO(p^3)$, solution vector $\sfu$ and load vector $\sfell$, both of the same size $\mcO(p^3)$. In DPG we enrich the test space usually by increasing the polynomial order in $\Delta p$ only for the test functions. Here, the single equation above is replaced by a larger system,

\begin{equation*}
\left(
\begin{array}{ccc}
    \sfG & \sfB & \tilde{\mathsf{B}}\\
    \mathsf{B}^\T & 0 & 0 \\
    \tilde{\mathsf{B}}^\T & 0 & 0
\end{array}
\right) \left(
\begin{array}{c}
\sfs \\
\sfu \\
\sfw
\end{array}
\right)=\left(
\begin{array}{c}
\sfell\\
0\\
0
\end{array}\right).
% \label{dpg_discrete_intro}
\end{equation*}
%
with additional unknowns $\sfs$ (size $\mcO((p+\Delta p)^3)$) and $\sfw$ (size $\mcO(p^2)$), and matrices $\sfG$ (square, size $\mcO(p+\Delta p)^3$),  $\sfB$ (resized to $\mcO((p+\Delta p)^3)\times\mcO(p^3)$) and $\tilde{\mathsf{B}}$ (size $\mcO((p+\Delta p)^3)\times\mcO(p^2)$), and load vector $\sfell$ (resized to $\mcO((p+\Delta p)^3)$). A conventional numerical integration of all these matrices has a complexity with leading terms of $\mcO((p+\Delta p)^9)+\mcO((p+\Delta p)^6p^3)$ floating point operations. Furthermore, we can retrieve a smaller symmetric system by statically condensing $\sfs$, obtaining
\begin{equation*}
\left(
\begin{array}{cc}
    \sfB^\T\sfG^{-1}\sfB & \sfB^\T\sfG^{-1}\tilde{\mathsf{B}}\\
    \tilde{\mathsf{B}}^\T\sfG^{-1}\sfB & \tilde{\mathsf{B}}^\T\sfG^{-1}\tilde{\mathsf{B}}
\end{array}
\right) \left(
\begin{array}{c}
\sfu \\
\sfw
\end{array}
\right)=\left(
\begin{array}{c}
\sfB^\T\sfG^{-1}\sfell\\
\tilde{\mathsf{B}}^\T\sfG^{-1}\sfell
\end{array}\right).
% \label{dpg_discrete3}
\end{equation*}

Reaching this point involves a cost of $\mcO((p+\Delta p)^9)$ operations for the Cholesky factorization and necessary substitution steps to get $G^{-1}\sfell$, $\mcO((p+\Delta p)^9p^3)$ for $G^{-1}\sfB$ and $G^{-1}\tilde{\sfB}$, and a leading cost of $\mcO(p^6(p+\Delta p)^6)$ for the final matrix-matrix multiplications. These costs are almost unavoidable in order to have a solution using the DPG methodology, and we can handle them in an efficient way using highly specialized linear algebra libraries, which results in a smaller CPU time. Thus, if we want to get time savings in this technique, the part on which we can focus is the construction of $\sfG$, $\sfB$, $\tilde{\sfB}$ and $\sfell$. Matrix $\sfG$, hereinafter referred to as the Gram matrix, is of special interest as it is the largest array within the element level calculations. Therefore, having as a basis the sum factorization approaches mentioned earlier, we aim in this paper to adapt those algorithms to the computation of $\sfG$ and finally obtain a significant saving in the implementation of DPG. In particular, we can easily extend these ideas to the integration of $\sfB$ if the variational formulation is the ultraweak. For more details on the derivation of the shown DPG system of equations see Section 3.

In the present paper, when deriving the algorithms we restrict ourselves to working with Gram matrices coming from the standard inner products only; however, it will be shown in one of the application cases that these ideas can also be extended to a more involved type of inner product. Moreover we restrict ourselves to real-valued functions for simplicity, but no major modification is anticipated when moving into complex-valued functions. We also work just on the hexahedron case. For the subject of FE shape functions, this article uses as a main reference the thorough review of shape functions for elements of all shapes done by Fuentes et al \cite{Fuentes2015}. We now outline the document: in Section 2, we explain the process of sum factorization and develop algorithms to apply the technique for all the Hilbert spaces belonging to the exact sequence; in Section 3, we provide several examples of DPG implementations and observe the computing time for the Gram matrix and other matrices, followed by a discussion. We will finally close the article with a few conclusions and mentions to possible future extensions of the present work.